#summary Flash-sim 项目的技术报告

= Algorithms =

== CMFT ==

Great cost gap exists between read and write a page for flash memory. CMFT is proposed by considering the cost of replacing a page and the popularity of that page. Next these two aspects will be analyzed separately. Cost varies between read and write operations. When reading a non-resident page, it will be loaded from flash using a read operation causing read cost which is the main purpose of hold a read-intensive page. However, sight difference exists while writing a page. When a dirty page is written again in the cache, these writes can be merged to one into the flash. Hence the potential future write of a dirty page becomes the leading cost saved after remaining a dirty page rather than what is usually considered the cost of flush this dirty page. The cost of flushing a page will eventually happen no matter how long it is delayed. On the other hand, if read operation often processed on a dirty page, this page should also be remained for the future read purpose. So what really matters are the potential read and write operations, rather than the current state (dirty or clean) of the page.

The estimation of the popularity of one page is a problem. Direct idea is adopting real access frequency of a page which uses the number of operations on one page in a certain period time. Another idea is adopting access interval, the operation number between two continuous on one page. However, these don’t fit this situation properly. The costs above are read and write a page in flash memory, which is corresponding to the occurring number of these operations. Real access to the flash takes place when a page misses from buffer. We use IRR (Inter-Reference Recency in paper LIRS) to reflect the potential replace possibility of the page. IRR is defined as the pages accessed between two continuous accesses to a page. The following table1 is an example of the IRR of a page.

||       ||   ||   ||   ||   ||   ||   ||   ||   ||   ||    || Recency || IRR ||
||   E   ||   ||   ||   ||   ||   ||   ||   ||   || x ||    || 0 || inf ||
||   D   ||   || x ||   ||   ||   ||   || x ||   ||   ||    || 2 || 3 ||
||   C   ||   ||   ||   || x ||   ||   ||   ||   ||   ||    || 4 || inf ||
||   B   ||   ||   || x ||   || x ||   ||   ||   ||   ||    || 3 || 1 ||
||   A   || x ||   ||   ||   ||   || x ||   || x ||   ||    || 1 || 1 ||
|| VTime || 1 || 2 || 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10 ||  ||  ||

Thus we have:  (Observation: the replace number of optimal replacement algorithm is no more than 2*IRR)

IRR reflects the page number needed between two continuous accesses to a page. And the page number needed reflects the possible replacement of this page, so IRR is adopted here to represent the popularity of a page. (Re access to a cache resident page B? reflect on IRR of B.) For a statistically Stable trace the average of several current IRR of one page estimate the popularity of one page more accurately, however this doesn’t response the trace change quickly. According to LRU-2, 2Q, the nearest two operations are enough to obtain the pattern of the page, so we only use the nearest IRR. The IRR can be calculated easily using a LRU queue, since when a page is accessed the distance between this page and the MRU one is IRR. (Example?)

This IRR can't adjust itself when a page is hot for a while and then not accessed forever. For example, if page A is read twice in a short time and never read forever, the very short IRR is recorded and never updated. This will make a cold page seems hot forever. So we use recency of a page to fix the IRR. The recency of a page is number of pages accessed after a page is accessed (see table1). The recency of a page is the potential future IRR, as the IRR never less than corresponding recency. We use average of recency and the IRR to reflect the hotness of one page.

CMFT gives each page a weight considering the popularity and the cost. The formula is defined as follows:
{{{
weight = readcost/(readrecency+readIRR) + writecost/(writerecency+writeIRR)
}}}

The weight is the estimation of the benefit to hold this page in cache. Each time the page with the lowest weight will be selected as victim (example needed). 

== Realization of CMFT ==

An access occurs to a page, this operation is recorded in an LRU Queue. Read and write operations to the same page are recorded as different entries in Queue. Each time a page is accessed the IRR is recorded. Read and write operations are recorded as different IRR. When a replacement is needed, the recency of a page is got and weight of each page is calculated using the above formula. The algorithm is as follows (algorithm needed).

The current CMFT is O(n). This is too slow to a cache replacement algorithm, especially for flash memory in which access cost is much less than disk. The main obstacle of IRR is getting the position of a page needs an array and the quick insert and delete of a page needs a list, they cannot realized on one queue in O(1) time complexity.

== Blow ==

The Blow algorithm is a simplification of CMFT using the same idea.  As the CMFT is an O(n) algorithm. The Blow is an O(1) algorithm in average. As it is very difficult to simulate the formula 1 using queue transformation, blow can recognize the dominate operation of each page and determines the victim by the dominate operation. 

The structure of Blow algorithm is illustrated in the figure2. Read and write operation rather than real pages are stored in separate queues. the MRU end of the queue are operations on the recently resident pages. Some additional nonresident operations are also stored in the LRU end of the queue for window sliding purpose.  A sliding window is on each queue. the window size is fixed to be half of the cache size, thus the two windows on each queue has the same size. The MRU end of the sliding window can be range from the MRU end of the queue and the last resident page in that queue. Each time either of the two sliding windows must at the last resident page, and we call this window locked. If a page is accessed (e.g. read), the read operation of that page is moved to the MRU end of the read queue, and if the page is nonresident before, the operation of write queue is moved from the nonresident part to the LRU end of the queue too. Once a page is hit in the sliding window, the sliding window will slide for a distance. A hit in the read sliding window will cause the read sliding window moves one operation on the read queue to the LRU end of read queue or write sliding window moves one operation to the MRU end. While a hit in the write sliding window will cause [writecost/readcost] distance to reflect different weight for write operation. The move will be processed on the non locked window first and if the window is lock then another window is moved. This can ensure at least one window is locked at any time.

[images/blow.gif]

When the cache is full, the resident page on the LRU side of the windows will be checked first from the LRU end, if they are not in the resident queue of the other queue it will be selected as victim. Or page will be get in read and write queue in turn, if the page is not in the other queue, it is determined to be the replacement page.(Algorithm..) This algorithm can be implemented in the O(1) time in average.(a proof need?) The best time state-of-art algorithm replacement for flash memory is also O(1) in average. 

=== Ananlysis ===

The Blow selects victim approximately according to the following formula: 
{{{
weight = max(readcost*read frequency, writecost*write frequency)
}}}

Proof:

First step: the reference frequency of each window is approximately writecost : readcost.

Second step: the victim selection process have the formula (readcost*read frequency ≈ writecost*write frequency)


Improvement with a single queue (next step work)